# Global loader_config.yaml

# Defines the number of rows to read from source files at a time.
# Larger chunks can be faster but use more memory.
chunk_size: 50000

# Defines the number of records to insert/upsert into the database at a time.
# Optimal batch size can vary based on database performance and network latency.
batch_size: 5000

# Maximum number of database connections to maintain in the pool.
# Adjust based on your database's capacity and expected load.
max_connections: 10

# Minimum number of idle database connections to maintain in the pool.
min_connections: 2

# Timeout in seconds for acquiring a database connection from the pool.
connection_timeout: 60

# Number of times to retry database operations or file processing in case of transient errors.
retry_attempts: 5

# Enable or disable progress tracking.
# If true, processing progress (processed files) will be saved to 'processing_progress.pkl',
# allowing for resuming interrupted operations.
enable_progress_tracking: True

# Enable or disable data validation checks.
# If true, the DataValidator will check for missing index/required columns,
# and potential data type inconsistencies.
enable_data_validation: True

# Enable or disable duplicate handling (upsert) during database loading.
# If true, the loader will attempt to update existing records if a conflict
# (based on IndexColumn in mapping) is detected, otherwise it will insert new records.
# If false, it will only attempt to insert records.
enable_duplicate_handling: True

#
timestamp_tolerance_seconds: 1.0
### Timestamp Tolerance Explanation
# The timestamp tolerance is a critical feature for handling small discrepancies in file timestamps that might occur due to:
# Without tolerance, even nanosecond differences would cause files to be reprocessed unnecessarily, leading to:
#- Duplicate data
#- Wasted processing resources
#- Potential data inconsistencies

#The tolerance window ensures stable and efficient processing while maintaining data integrity.





